---
sidebar_position: 1
---

import useBaseUrl from '@docusaurus/useBaseUrl';
import Admonition from '@theme/Admonition';

# Azure

## How to connect Databricks using Lakehouse Federation

### Create A Lakehouse Federation Connection Video Walkthrough
<br />
<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/_2AkgukfB8Q"
  title="Create A Lakehouse Federation Connection in Azure Databricks"
  frameBorder="0"
  allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
></iframe>

1. Navigate to the Databricks workspace
2. In the left sidebar, click on "Catalog" and then click on "External Data" 

<div style={{textAlign: 'left'}}>
  <img src={useBaseUrl('/img/aws/aws_external_data_buttom.png')} 
  alt="external data buttom"
  style={{width: '80%', height: 'auto'}}
  
  />
</div>
<br />

3. Click on "Connections"
<div style={{textAlign: 'left'}}>
  <img src={useBaseUrl('/img/aws/addconnectionbuttom.png')} 
  alt="external data buttom"
  style={{width: '80%', height: 'auto'}}
  
  />
</div>
<br />


4. **Configure your connection:**
   - **Connection name**: Enter a descriptive name for your data source connection
   - **Connection type**: Select the appropriate connector for your external system (e.g., PostgreSQL, MySQL, SQL Server, Snowflake, etc.)
  
   <br />
 
   <Admonition type="tip" title="Available Connection Types">
     For a complete list of supported connectors, see the [Databricks Lakehouse Federation documentation](https://learn.microsoft.com/en-us/azure/databricks/query-federation/).
   </Admonition>

5. **Configure network connectivity:**
   - Ensure your external data source is reachable from Databricks
   - Configure appropriate security groups, VPC settings, or firewall rules
   - For on-premises systems, you may need VPN or dedicated network connections
   
6. **Test and create the connection:**
   - Click **Test Connection** to verify connectivity
   - Once successful, click **Create** to save your external data connection

<Admonition type="info" title="Next Steps">
  After creating your connection, you can create catalogs and query external tables directly from Databricks SQL or notebooks.
</Admonition>

## How to setup Lakeflow Connection

<br />
<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/yPOmCVzpqfw"
  title="Create a Lakeflow Connect Pipeline in AWS Databricks"
  frameBorder="0"
  allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
></iframe>

[Databricks Lakeflow Connect Documentation](https://learn.microsoft.com/en-us/azure/databricks/ingestion/overview)